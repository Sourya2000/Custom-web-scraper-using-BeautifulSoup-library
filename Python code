from bs4 import BeautifulSoup
import requests

response = requests.get("https://news.ycombinator.com")  #HackerNews website
print(response.text)


yc= response.text
souplive = BeautifulSoup(yc,"html.parser")
print(souplive.title)

print(souplive.find(name="a",class_="titlelink").getText())

article_tag =souplive.find(name="a",class_="titlelink")
article_link = article_tag.get("href")
print(article_link)
article_upvote= souplive.find(name="span",class_="score").getText()
print(article_upvote)

article_tags= souplive.find_all(name="a",class_="titlelink")
article_upvote= souplive.find_all(name="span",class_="score")
art_txt=[]
art_link=[]
for article in article_tags:
    link= article.get("href")
    art_link.append(link)
    up=article.getText()
    art_txt.append(up)

article_upvotes =[score.getText()for score in article_upvote] # list comprehension

print(art_link)
print(art_txt)
print(article_upvotes)

article_upvotes =[int(score.getText().split()[0])for score in article_upvote]
print(article_upvotes )# list comprehension


print(int(article_upvotes[0].split()[0]))

print(art_link)

largest = max(article_upvotes)
print(largest)

largest_index = article_upvotes.index(largest)
print(largest_index)


print(art_link[19])
print(art_up[19])


import pandas
data_diction={ "links" : art_link,"names": art_txt,"upvote": article_upvotes
}
data = pandas.DataFrame.from_dict(data_diction,orient="index")

print(data)


import csv
data_csv = data.to_csv( )

